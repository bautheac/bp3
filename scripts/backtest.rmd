---
title: "backtest"
author: "Olivier"
date: "`r Sys.Date()`"
output:
  md_document:
    variant: markdown_github
---

```{r setup, include = F}
library(magrittr)
knitr::opts_chunk$set(echo = T, cache = T, comment = "#>")
```


## Load

I load the data into two dataframes here; one for historical data ('data_price_etf.csv' in the original github repo) and one for qualitative data ('data_static_etf_com.csv').
```{r load, message = F, warning = F}
historic <- readr::read_csv(file = "../data/data_historic_etf.csv") %>%
  dplyr::mutate(Date = as.Date(Date)) %>% dplyr::arrange(Date) %>%
  tidyr::gather(`name`, price, -Date) %>% dplyr::mutate(price = as.numeric(price)) %>% 
  dplyr::filter(complete.cases(.))
static <- readr::read_csv(file = "../data/data_static_etf.csv")
```

## Transform

To my understanding, feature engineering here involves calculating statistics as well as constructing TDA features at regular interval (monthly) from the time series data at regular interval (monthly). The resulting dataframe would contain, for each month, one sample per name (ETF) where features include time series statistics, TDA value(s?) as well as qualitative information (static dataframe).

### Historic features

I understand that time series statistics include return, high minus low as well as volatility over various time horizons including past week, past 4 weeks, past 8 weeks, past 13 weeks, past 26 weeks, past 52 weeks.

#### Returns

I calculate returns as the relative change in price over the above-mentioned time horizons here.
```{r returns, message = F, warning = F}
sizes <- dplyr::group_by(historic, `name`) %>% dplyr::summarise(n = n())

historic %<>% dplyr::group_by(`name`) %>% dplyr::left_join(sizes, by = "name") %>%
  dplyr::mutate(
    `return - 1w` = price / dplyr::lag(price, n = 1L) - 1L,
    `return - 4w` = price / dplyr::lag(price, n = 4L) - 1L,
    `return - 8w` = price / dplyr::lag(price, n = 8L) - 1L,
    `return - 13w` = price / dplyr::lag(price, n = 13L) - 1L,
    `return - 26w` = price / dplyr::lag(price, n = 26L) - 1L,
    `return - 52w` = price / dplyr::lag(price, n = 52L) - 1L
    )

remove(sizes)
```

#### High - low

I calculate high minus low by substracting the minimum observed value from the maximum observed value over the above-mentioned time horizons here.
```{r `high - low`, message = F, warning = F}
`high - low` <- function(x) max(x) - min(x)

`high - low - 4w` <- tibbletime::rollify(`high - low`, window = 4L)
`high - low - 8w` <- tibbletime::rollify(`high - low`, window = 8L)
`high - low - 13w` <- tibbletime::rollify(`high - low`, window = 13L)
`high - low - 26w` <- tibbletime::rollify(`high - low`, window = 26L)
`high - low - 52w` <- tibbletime::rollify(`high - low`, window = 52L)

historic %<>% dplyr::mutate(
  `high - low - 4w` = `high - low - 4w`(price),
  `high - low - 8w` = `high - low - 8w`(price),
  `high - low - 13w` = `high - low - 13w`(price),
  `high - low - 26w` = ifelse(`n` > 26L, `high - low - 26w`(price), NA),
  `high - low - 52w` = ifelse(`n` > 52L, `high - low - 52w`(price), NA)
  )

remove(`high - low`, `high - low - 4w`, `high - low - 8w`, 
       `high - low - 13w`, `high - low - 26w`, `high - low - 52w`)
```

#### Volatility

I calculate volatility as the annualized standard deviation of 1-week returns over the above-mentioned time horizons here.
```{r volatility, message = F, warning = F}
`volatility` <- function(x) sd(x, na.rm = T) * sqrt(52L)

`volatility - 4w` <- tibbletime::rollify(`volatility`, window = 4L)
`volatility - 8w` <- tibbletime::rollify(`volatility`, window = 8L)
`volatility - 13w` <- tibbletime::rollify(`volatility`, window = 13L)
`volatility - 26w` <- tibbletime::rollify(`volatility`, window = 26L)
`volatility - 52w` <- tibbletime::rollify(`volatility`, window = 52L)

historic %<>% dplyr::mutate(
  `volatility - 4w` = `volatility - 4w`(`return - 1w`),
  `volatility - 8w` = `volatility - 8w`(`return - 1w`),
  `volatility - 13w` = `volatility - 13w`(`return - 1w`),
  `volatility - 26w` = ifelse(`n` > 26L, `volatility - 26w`(`return - 1w`), NA),
  `volatility - 52w` = ifelse(`n` > 52L, `volatility - 52w`(`return - 1w`), NA)
  )

remove(`volatility`, `volatility - 4w`, `volatility - 8w`, 
       `volatility - 13w`, `volatility - 26w`, `volatility - 52w`)
saveRDS(historic, file = "../data/historic.rds")
```

#### TDA
I get stuck here. To my undertanding there should be TDA feature(s?) for every month and name with the feature(s?) generated by feeding the previous 52-week price history to TDA functions. The output dataset in the original github repo shows 100 values (columns) for each name (row):
```{r TDA, message = F, warning = F}
head(read.csv("../data/001_data_prices_20072007_18072008.csv"))
```
Are there 100 TDA features? If so, why is there only 1 set of value(s?), was expecting TDA values for each month.

#### Wrap up
```{r `historic final`, message = F, warning = F}
historic <- readRDS(file = "../data/historic.rds")
historic %<>% dplyr::mutate(year = lubridate::year(Date), month = lubridate::month(Date), date = Date) %>%
  dplyr::group_by(name, year, month) %>% dplyr::filter(dplyr::row_number() == n()) %>% 
  dplyr::ungroup() %>% dplyr::select(-c("Date", "n", "year", "month")) %>% 
  tidyr::gather(feature, value, -c("date", "name"))
```


